{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e9d46c-3b65-4589-8f96-bc25b1bb6439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de ventas de videojuegos cargado exitosamente.\n",
      "   Rank                      Name Platform    Year         Genre Publisher  \\\n",
      "0     1                Wii Sports      Wii  2006.0        Sports  Nintendo   \n",
      "1     2         Super Mario Bros.      NES  1985.0      Platform  Nintendo   \n",
      "2     3            Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
      "3     4         Wii Sports Resort      Wii  2009.0        Sports  Nintendo   \n",
      "4     5  Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
      "\n",
      "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
      "0     41.49     29.02      3.77         8.46         82.74  \n",
      "1     29.08      3.58      6.81         0.77         40.24  \n",
      "2     15.85     12.88      3.79         3.31         35.82  \n",
      "3     15.75     11.01      3.28         2.96         33.00  \n",
      "4     11.27      8.89     10.22         1.00         31.37  \n",
      "\n",
      "Dataset de películas de IMDb cargado exitosamente.\n",
      "    movie_id                         movie_name  year certificate  runtime  \\\n",
      "0  tt9114286     Black Panther: Wakanda Forever  2022       PG-13  161 min   \n",
      "1  tt1630029           Avatar: The Way of Water  2022       PG-13  192 min   \n",
      "2  tt5884796                              Plane  2023           R  107 min   \n",
      "3  tt6710474  Everything Everywhere All at Once  2022           R  139 min   \n",
      "4  tt5433140                             Fast X  2023         NaN      NaN   \n",
      "\n",
      "                        genre  rating  \\\n",
      "0    Action, Adventure, Drama     6.9   \n",
      "1  Action, Adventure, Fantasy     7.8   \n",
      "2            Action, Thriller     6.5   \n",
      "3   Action, Adventure, Comedy     8.0   \n",
      "4      Action, Crime, Mystery     NaN   \n",
      "\n",
      "                                         description  \\\n",
      "0  The people of Wakanda fight to protect their h...   \n",
      "1  Jake Sully lives with his newfound family form...   \n",
      "2  A pilot finds himself caught in a war zone aft...   \n",
      "3  A middle-aged Chinese immigrant is swept up in...   \n",
      "4  Dom Toretto and his family are targeted by the...   \n",
      "\n",
      "                       director       director_id  \\\n",
      "0                  Ryan Coogler  /name/nm3363032/   \n",
      "1                 James Cameron  /name/nm0000116/   \n",
      "2         Jean-FranÃ§ois Richet  /name/nm0724938/   \n",
      "3  Dan Kwan, \\nDaniel Scheinert  /name/nm3453283/   \n",
      "4               Louis Leterrier  /name/nm0504642/   \n",
      "\n",
      "                                                star  \\\n",
      "0  Letitia Wright, \\nLupita Nyong'o, \\nDanai Guri...   \n",
      "1  Sam Worthington, \\nZoe Saldana, \\nSigourney We...   \n",
      "2  Gerard Butler, \\nMike Colter, \\nTony Goldwyn, ...   \n",
      "3  Michelle Yeoh, \\nStephanie Hsu, \\nJamie Lee Cu...   \n",
      "4  Vin Diesel, \\nJordana Brewster, \\nTyrese Gibso...   \n",
      "\n",
      "                                             star_id     votes  gross(in $)  \n",
      "0  /name/nm4004793/,/name/nm2143282/,/name/nm1775...  204835.0          NaN  \n",
      "1  /name/nm0941777/,/name/nm0757855/,/name/nm0000...  295119.0          NaN  \n",
      "2  /name/nm0124930/,/name/nm1591496/,/name/nm0001...   26220.0          NaN  \n",
      "3  /name/nm3215397/,/name/nm0000706/,/name/nm3513...  327858.0          NaN  \n",
      "4  /name/nm0004874/,/name/nm0108287/,/name/nm0879...       NaN          NaN  \n",
      "\n",
      "Dataset de reseñas de Yelp cargado exitosamente.\n",
      "                                                text  stars\n",
      "0  If you decide to eat here, just be aware it is...      3\n",
      "1  I've taken a lot of spin classes over the year...      5\n",
      "2  Family diner. Had the buffet. Eclectic assortm...      3\n",
      "3  Wow!  Yummy, different,  delicious.   Our favo...      5\n",
      "4  Cute interior and owner (?) gave us tour of up...      4\n"
     ]
    }
   ],
   "source": [
    "# Importación de las bibliotecas \n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import sqlite3\n",
    "import redis\n",
    "\n",
    "# Parte 1: Volver a cargar los datasets en pandas\n",
    "# Fuente 1: Kaggle - Video Game Sales: https://www.kaggle.com/datasets/gregorut/videogamesales\n",
    "# Fuente 2: Kaggle - IMDb Movies extensive dataset: https://www.kaggle.com/datasets/rajugc/imdb-movies-dataset-based-on-genre\n",
    "# Fuente 3: Yelp Open Dataset: https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset/data\n",
    "\n",
    "# Carga de Datos de Videojuegos y Cine\n",
    "try:\n",
    "    # Dataset de ventas de videojuegos\n",
    "    df_vgsales = pd.read_csv('vgsales.csv')\n",
    "    print(\"Dataset de ventas de videojuegos cargado exitosamente.\")\n",
    "    print(df_vgsales.head())\n",
    "\n",
    "    # Dataset de de películas\n",
    "    df_movies = pd.read_csv('IMDb_movies.csv', encoding='latin1')\n",
    "    print(\"\\nDataset de películas de IMDb cargado exitosamente.\")\n",
    "    print(df_movies.head())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: No se encontró el archivo. Asegúrate de que el nombre del archivo es correcto y que lo has subido a Colab.\")\n",
    "    print(e)\n",
    "\n",
    "\n",
    "# Carga de Datos de Restaurantes (Yelp)\n",
    "try:\n",
    "    # Usamos lines=True para leer el archivo correctamente.\n",
    "    df_yelp_reviews = pd.read_json('yelp_academic_dataset_review.json', lines=True, nrows=500000)\n",
    "    print(\"\\nDataset de reseñas de Yelp cargado exitosamente.\")\n",
    "    # Nos interesan principalmente el texto de la reseña y las estrellas\n",
    "    df_yelp_reviews_sample = df_yelp_reviews[['text', 'stars']]\n",
    "    print(df_yelp_reviews_sample.head())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: No se encontró el archivo de Yelp. Asegúrate de que el nombre del archivo es correcto.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f78e26d7-4539-4a66-983a-ecfac0d09a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16598 entries, 0 to 16597\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Rank          16598 non-null  int64  \n",
      " 1   Name          16598 non-null  object \n",
      " 2   Platform      16598 non-null  object \n",
      " 3   Year          16327 non-null  float64\n",
      " 4   Genre         16598 non-null  object \n",
      " 5   Publisher     16540 non-null  object \n",
      " 6   NA_Sales      16598 non-null  float64\n",
      " 7   EU_Sales      16598 non-null  float64\n",
      " 8   JP_Sales      16598 non-null  float64\n",
      " 9   Other_Sales   16598 non-null  float64\n",
      " 10  Global_Sales  16598 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_vgsales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d1e4d12-dcbf-497b-8ad2-02cfaf410d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 368300 entries, 0 to 368299\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   movie_id     368300 non-null  object \n",
      " 1   movie_name   368296 non-null  object \n",
      " 2   year         315052 non-null  object \n",
      " 3   certificate  104191 non-null  object \n",
      " 4   runtime      259146 non-null  object \n",
      " 5   genre        368300 non-null  object \n",
      " 6   rating       230938 non-null  float64\n",
      " 7   description  368300 non-null  object \n",
      " 8   director     340931 non-null  object \n",
      " 9   director_id  340931 non-null  object \n",
      " 10  star         309605 non-null  object \n",
      " 11  star_id      316442 non-null  object \n",
      " 12  votes        230942 non-null  float64\n",
      " 13  gross(in $)  25039 non-null   float64\n",
      "dtypes: float64(3), object(11)\n",
      "memory usage: 39.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "082f933b-1f3b-47c4-9fa0-3018c91627d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   review_id    500000 non-null  object        \n",
      " 1   user_id      500000 non-null  object        \n",
      " 2   business_id  500000 non-null  object        \n",
      " 3   stars        500000 non-null  int64         \n",
      " 4   useful       500000 non-null  int64         \n",
      " 5   funny        500000 non-null  int64         \n",
      " 6   cool         500000 non-null  int64         \n",
      " 7   text         500000 non-null  object        \n",
      " 8   date         500000 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(4), object(4)\n",
      "memory usage: 34.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_yelp_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4095d1f0-52ac-4426-bc14-51e1890b383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2376 entries, 0 to 2375\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         2376 non-null   object\n",
      " 1   metascore     2376 non-null   object\n",
      " 2   release_date  2376 non-null   object\n",
      " 3   summary       2376 non-null   object\n",
      " 4   url           2376 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 92.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_metacritic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a26b5c24-3838-40bd-ab21-d4fa6c2f6999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Limpieza de df_vgsales ---\n",
      "Información del DataFrame df_vgsales después de la limpieza:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16327 entries, 0 to 16597\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Rank          16327 non-null  int64  \n",
      " 1   Name          16327 non-null  object \n",
      " 2   Platform      16327 non-null  object \n",
      " 3   Year          16327 non-null  int64  \n",
      " 4   Genre         16327 non-null  object \n",
      " 5   Publisher     16327 non-null  object \n",
      " 6   NA_Sales      16327 non-null  float64\n",
      " 7   EU_Sales      16327 non-null  float64\n",
      " 8   JP_Sales      16327 non-null  float64\n",
      " 9   Other_Sales   16327 non-null  float64\n",
      " 10  Global_Sales  16327 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(4)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      "Primeras filas del DataFrame limpio:\n",
      "   Rank                      Name Platform  Year         Genre Publisher  \\\n",
      "0     1                Wii Sports      Wii  2006        Sports  Nintendo   \n",
      "1     2         Super Mario Bros.      NES  1985      Platform  Nintendo   \n",
      "2     3            Mario Kart Wii      Wii  2008        Racing  Nintendo   \n",
      "3     4         Wii Sports Resort      Wii  2009        Sports  Nintendo   \n",
      "4     5  Pokemon Red/Pokemon Blue       GB  1996  Role-Playing  Nintendo   \n",
      "\n",
      "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
      "0     41.49     29.02      3.77         8.46         82.74  \n",
      "1     29.08      3.58      6.81         0.77         40.24  \n",
      "2     15.85     12.88      3.79         3.31         35.82  \n",
      "3     15.75     11.01      3.28         2.96         33.00  \n",
      "4     11.27      8.89     10.22         1.00         31.37  \n"
     ]
    }
   ],
   "source": [
    "# Parte 2: Limpieza de df_vgsales\n",
    "\n",
    "# 2.1. Limpieza de df_vgsales\n",
    "print(\"--- Limpieza de df_vgsales ---\")\n",
    "# Se hace una copia para no modificar el original\n",
    "df_vgsales_clean = df_vgsales.copy()\n",
    "\n",
    "# 1. Manejo de valores nulos\n",
    "# Rellenamos los Publishers faltantes con 'Unknown' (LÍNEA CORREGIDA)\n",
    "df_vgsales_clean['Publisher'] = df_vgsales_clean['Publisher'].fillna('Unknown')\n",
    "\n",
    "# Eliminamos las filas donde el año es nulo, ya que es un dato importante\n",
    "df_vgsales_clean.dropna(subset=['Year'], inplace=True)\n",
    "\n",
    "# 2. Corrección de tipos de datos\n",
    "# Convertimos el año de float (ej. 2006.0) a entero (ej. 2006)\n",
    "df_vgsales_clean['Year'] = df_vgsales_clean['Year'].astype(int)\n",
    "\n",
    "# 3. Verificación\n",
    "print(\"Información del DataFrame df_vgsales después de la limpieza:\")\n",
    "df_vgsales_clean.info()\n",
    "\n",
    "print(\"\\nPrimeras filas del DataFrame limpio:\")\n",
    "print(df_vgsales_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cb4893b-75a6-4695-b914-8b3823376d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.49</td>\n",
       "      <td>29.02</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.46</td>\n",
       "      <td>82.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.85</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.31</td>\n",
       "      <td>35.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.75</td>\n",
       "      <td>11.01</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.96</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16593</th>\n",
       "      <td>16596</td>\n",
       "      <td>Woody Woodpecker in Crazy Castle 5</td>\n",
       "      <td>GBA</td>\n",
       "      <td>2002</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Kemco</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16594</th>\n",
       "      <td>16597</td>\n",
       "      <td>Men in Black II: Alien Escape</td>\n",
       "      <td>GC</td>\n",
       "      <td>2003</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>Infogrames</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16595</th>\n",
       "      <td>16598</td>\n",
       "      <td>SCORE International Baja 1000: The Official Game</td>\n",
       "      <td>PS2</td>\n",
       "      <td>2008</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Activision</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16596</th>\n",
       "      <td>16599</td>\n",
       "      <td>Know How 2</td>\n",
       "      <td>DS</td>\n",
       "      <td>2010</td>\n",
       "      <td>Puzzle</td>\n",
       "      <td>7G//AMES</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16597</th>\n",
       "      <td>16600</td>\n",
       "      <td>Spirits &amp; Spells</td>\n",
       "      <td>GBA</td>\n",
       "      <td>2003</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Wanadoo</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16327 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rank                                              Name Platform  Year  \\\n",
       "0          1                                        Wii Sports      Wii  2006   \n",
       "1          2                                 Super Mario Bros.      NES  1985   \n",
       "2          3                                    Mario Kart Wii      Wii  2008   \n",
       "3          4                                 Wii Sports Resort      Wii  2009   \n",
       "4          5                          Pokemon Red/Pokemon Blue       GB  1996   \n",
       "...      ...                                               ...      ...   ...   \n",
       "16593  16596                Woody Woodpecker in Crazy Castle 5      GBA  2002   \n",
       "16594  16597                     Men in Black II: Alien Escape       GC  2003   \n",
       "16595  16598  SCORE International Baja 1000: The Official Game      PS2  2008   \n",
       "16596  16599                                        Know How 2       DS  2010   \n",
       "16597  16600                                  Spirits & Spells      GBA  2003   \n",
       "\n",
       "              Genre   Publisher  NA_Sales  EU_Sales  JP_Sales  Other_Sales  \\\n",
       "0            Sports    Nintendo     41.49     29.02      3.77         8.46   \n",
       "1          Platform    Nintendo     29.08      3.58      6.81         0.77   \n",
       "2            Racing    Nintendo     15.85     12.88      3.79         3.31   \n",
       "3            Sports    Nintendo     15.75     11.01      3.28         2.96   \n",
       "4      Role-Playing    Nintendo     11.27      8.89     10.22         1.00   \n",
       "...             ...         ...       ...       ...       ...          ...   \n",
       "16593      Platform       Kemco      0.01      0.00      0.00         0.00   \n",
       "16594       Shooter  Infogrames      0.01      0.00      0.00         0.00   \n",
       "16595        Racing  Activision      0.00      0.00      0.00         0.00   \n",
       "16596        Puzzle    7G//AMES      0.00      0.01      0.00         0.00   \n",
       "16597      Platform     Wanadoo      0.01      0.00      0.00         0.00   \n",
       "\n",
       "       Global_Sales  \n",
       "0             82.74  \n",
       "1             40.24  \n",
       "2             35.82  \n",
       "3             33.00  \n",
       "4             31.37  \n",
       "...             ...  \n",
       "16593          0.01  \n",
       "16594          0.01  \n",
       "16595          0.01  \n",
       "16596          0.01  \n",
       "16597          0.01  \n",
       "\n",
       "[16327 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vgsales_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46e6b60c-672b-4812-98d1-9b4c95a9a4f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Limpieza de df_movies ---\n",
      "Información del DataFrame df_movies después de la limpieza:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 302236 entries, 0 to 368299\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   movie_id          302236 non-null  object \n",
      " 1   movie_name        302236 non-null  object \n",
      " 2   year              302236 non-null  int64  \n",
      " 3   certificate       302236 non-null  object \n",
      " 4   runtime           302236 non-null  int64  \n",
      " 5   genre             302236 non-null  object \n",
      " 6   rating            302236 non-null  float64\n",
      " 7   description       302236 non-null  object \n",
      " 8   director          302236 non-null  object \n",
      " 9   director_id       299440 non-null  object \n",
      " 10  star              302236 non-null  object \n",
      " 11  star_id           293627 non-null  object \n",
      " 12  votes             302236 non-null  int64  \n",
      " 13  gross_in_dollars  302236 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(9)\n",
      "memory usage: 34.6+ MB\n",
      "\n",
      "Primeras filas del DataFrame limpio:\n",
      "    movie_id                         movie_name  year certificate  runtime  \\\n",
      "0  tt9114286     Black Panther: Wakanda Forever  2022       PG-13      161   \n",
      "1  tt1630029           Avatar: The Way of Water  2022       PG-13      192   \n",
      "2  tt5884796                              Plane  2023           R      107   \n",
      "3  tt6710474  Everything Everywhere All at Once  2022           R      139   \n",
      "4  tt5433140                             Fast X  2023     Unknown       95   \n",
      "\n",
      "                        genre    rating  \\\n",
      "0    Action, Adventure, Drama  6.900000   \n",
      "1  Action, Adventure, Fantasy  7.800000   \n",
      "2            Action, Thriller  6.500000   \n",
      "3   Action, Adventure, Comedy  8.000000   \n",
      "4      Action, Crime, Mystery  5.831802   \n",
      "\n",
      "                                         description  \\\n",
      "0  The people of Wakanda fight to protect their h...   \n",
      "1  Jake Sully lives with his newfound family form...   \n",
      "2  A pilot finds himself caught in a war zone aft...   \n",
      "3  A middle-aged Chinese immigrant is swept up in...   \n",
      "4  Dom Toretto and his family are targeted by the...   \n",
      "\n",
      "                       director       director_id  \\\n",
      "0                  Ryan Coogler  /name/nm3363032/   \n",
      "1                 James Cameron  /name/nm0000116/   \n",
      "2         Jean-FranÃ§ois Richet  /name/nm0724938/   \n",
      "3  Dan Kwan, \\nDaniel Scheinert  /name/nm3453283/   \n",
      "4               Louis Leterrier  /name/nm0504642/   \n",
      "\n",
      "                                                star  \\\n",
      "0  Letitia Wright, \\nLupita Nyong'o, \\nDanai Guri...   \n",
      "1  Sam Worthington, \\nZoe Saldana, \\nSigourney We...   \n",
      "2  Gerard Butler, \\nMike Colter, \\nTony Goldwyn, ...   \n",
      "3  Michelle Yeoh, \\nStephanie Hsu, \\nJamie Lee Cu...   \n",
      "4  Vin Diesel, \\nJordana Brewster, \\nTyrese Gibso...   \n",
      "\n",
      "                                             star_id   votes  gross_in_dollars  \n",
      "0  /name/nm4004793/,/name/nm2143282/,/name/nm1775...  204835               0.0  \n",
      "1  /name/nm0941777/,/name/nm0757855/,/name/nm0000...  295119               0.0  \n",
      "2  /name/nm0124930/,/name/nm1591496/,/name/nm0001...   26220               0.0  \n",
      "3  /name/nm3215397/,/name/nm0000706/,/name/nm3513...  327858               0.0  \n",
      "4  /name/nm0004874/,/name/nm0108287/,/name/nm0879...    9622               0.0  \n"
     ]
    }
   ],
   "source": [
    "# 2.2. Limpieza de df_movies\n",
    "print(\"\\n--- Limpieza de df_movies ---\")\n",
    "df_movies_clean = df_movies.copy()\n",
    "\n",
    "# 1. Se renombra las columnas con caracteres especiales\n",
    "df_movies_clean = df_movies_clean.rename(columns={'gross(in $)': 'gross_in_dollars'})\n",
    "\n",
    "# 2. Valores nulos y tipos de datos\n",
    "# Eliminar filas donde el nombre de la película es nulo\n",
    "df_movies_clean.dropna(subset=['movie_name'], inplace=True)\n",
    "\n",
    "# Se limpiea y se convierte 'Year'\n",
    "# pd.to_numeric convierte a número, y los errores (texto) se convierten en NaT (Not a Time)\n",
    "df_movies_clean['year'] = pd.to_numeric(df_movies_clean['year'], errors='coerce')\n",
    "df_movies_clean.dropna(subset=['year'], inplace=True) # Eliminar filas con años no válidos\n",
    "df_movies_clean['year'] = df_movies_clean['year'].astype(int)\n",
    "\n",
    "# Se limpia y se convierte 'runtime' (ej. '131 min.' -> 131)\n",
    "df_movies_clean['runtime'] = df_movies_clean['runtime'].str.extract(r'(\\d+)').astype(float)\n",
    "# Rellenar los nulos de 'runtime' con la media de la columna\n",
    "runtime_mean = df_movies_clean['runtime'].mean()\n",
    "df_movies_clean['runtime'] = df_movies_clean['runtime'].fillna(runtime_mean)\n",
    "df_movies_clean['runtime'] = df_movies_clean['runtime'].astype(int)\n",
    "\n",
    "# Se rellena 'rating' y 'votes' con la media\n",
    "rating_mean = df_movies_clean['rating'].mean()\n",
    "votes_mean = df_movies_clean['votes'].mean()\n",
    "df_movies_clean['rating'] = df_movies_clean['rating'].fillna(rating_mean)\n",
    "df_movies_clean['votes'] = df_movies_clean['votes'].fillna(votes_mean)\n",
    "df_movies_clean['votes'] = df_movies_clean['votes'].astype(int)\n",
    "\n",
    "\n",
    "# Se rellenan las columnas de texto faltantes\n",
    "text_cols = ['certificate', 'director', 'star']\n",
    "for col in text_cols:\n",
    "    df_movies_clean[col] = df_movies_clean[col].fillna('Unknown')\n",
    "\n",
    "# La columna 'gross_in_dollars' tiene demasiados nulos para rellenar, la dejamos así por ahora.\n",
    "# Simplemente rellenamos con 0 para mantener un tipo de dato consistente.\n",
    "df_movies_clean['gross_in_dollars'] = df_movies_clean['gross_in_dollars'].fillna(0)\n",
    "\n",
    "\n",
    "# 3. Verificación\n",
    "print(\"Información del DataFrame df_movies después de la limpieza:\")\n",
    "df_movies_clean.info()\n",
    "\n",
    "print(\"\\nPrimeras filas del DataFrame limpio:\")\n",
    "print(df_movies_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17865cdf-47e9-4b28-af9b-8306c0be4734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Limpieza de df_yelp_reviews ---\n",
      "Información del DataFrame df_yelp_reviews después de la limpieza:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   review_id    500000 non-null  object        \n",
      " 1   business_id  500000 non-null  object        \n",
      " 2   stars        500000 non-null  int64         \n",
      " 3   text         500000 non-null  object        \n",
      " 4   date         500000 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(1), object(3)\n",
      "memory usage: 19.1+ MB\n",
      "\n",
      "Primeras filas del DataFrame limpio:\n",
      "                review_id             business_id  stars  \\\n",
      "0  KU_O5udG6zpxOg-VcAEodg  XQfwVwDr-v0ZS3_CbbE5Xw      3   \n",
      "1  BiTunyQ73aT9WBnpR9DZGw  7ATYjTIgM3jUlt4UM3IypQ      5   \n",
      "2  saUsX_uimxRlCVr67Z4Jig  YjUWPpI6HXG530lwP-fb2A      3   \n",
      "3  AqPFMleE6RsU23_auESxiA  kxX2SOes4o-D3ZQBkiMRfA      5   \n",
      "4  Sx8TMOWLNuJBWer-0pcmoA  e4Vwtrqf-wpJfwesgvdgxQ      4   \n",
      "\n",
      "                                                text                date  \n",
      "0  if you decide to eat here, just be aware it is... 2018-07-07 22:09:11  \n",
      "1  i've taken a lot of spin classes over the year... 2012-01-03 15:28:18  \n",
      "2  family diner. had the buffet. eclectic assortm... 2014-02-05 20:30:30  \n",
      "3  wow!  yummy, different,  delicious.   our favo... 2015-01-04 00:01:03  \n",
      "4  cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15  \n"
     ]
    }
   ],
   "source": [
    "# 2.3. Limpieza de df_yelp_reviews\n",
    "print(\"\\n--- Limpieza de df_yelp_reviews ---\")\n",
    "df_yelp_clean = df_yelp_reviews.copy()\n",
    "\n",
    "# 1. Se seleccionan de columnas\n",
    "# Nos quedamos con las columnas más relevantes para nuestro análisis\n",
    "df_yelp_clean = df_yelp_clean[['review_id', 'business_id', 'stars', 'text', 'date']]\n",
    "\n",
    "# 2. Se limpia el texto\n",
    "# Se conveirte todo el texto de las reseñas a minúsculas\n",
    "df_yelp_clean['text'] = df_yelp_clean['text'].str.lower()\n",
    "\n",
    "# 3. Verificación\n",
    "print(\"Información del DataFrame df_yelp_reviews después de la limpieza:\")\n",
    "df_yelp_clean.info()\n",
    "print(\"\\nPrimeras filas del DataFrame limpio:\")\n",
    "print(df_yelp_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7b29da2-c4c3-4d2b-965c-18567b5727e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Limpieza de df_metacritic ---\n",
      "Información del DataFrame df_metacritic después de la limpieza:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2376 entries, 0 to 2375\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   title         2376 non-null   object        \n",
      " 1   metascore     2376 non-null   int64         \n",
      " 2   release_date  2376 non-null   datetime64[ns]\n",
      " 3   summary       2376 non-null   object        \n",
      " 4   url           2376 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(3)\n",
      "memory usage: 92.9+ KB\n",
      "\n",
      "Primeras filas del DataFrame limpio:\n",
      "                          title  metascore release_date  \\\n",
      "0  Disco Elysium: The Final Cut         97   2021-03-30   \n",
      "1                   Half-Life 2         96   2004-11-16   \n",
      "2            Grand Theft Auto V         96   2015-04-13   \n",
      "3               Baldur's Gate 3         96   2023-08-03   \n",
      "4                The Orange Box         96   2007-10-10   \n",
      "\n",
      "                                             summary  \\\n",
      "0  Disco Elysium - The Final Cut is the definitiv...   \n",
      "1  [Metacritic's 2004 PC Game of the Year]  By ta...   \n",
      "2  Los Santos is a vast, sun-soaked metropolis fu...   \n",
      "3  An ancient evil has returned to Baldur's Gate,...   \n",
      "4  Games included in The Orange Box compilation: ...   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.metacritic.com/game/disco-elysium-...  \n",
      "1       https://www.metacritic.com/game/half-life-2/  \n",
      "2  https://www.metacritic.com/game/grand-theft-au...  \n",
      "3    https://www.metacritic.com/game/baldurs-gate-3/  \n",
      "4    https://www.metacritic.com/game/the-orange-box/  \n"
     ]
    }
   ],
   "source": [
    "# 2.4. Limpieza de df_metacritic\n",
    "print(\"\\n--- Limpieza de df_metacritic ---\")\n",
    "df_metacritic_clean = df_metacritic.copy()\n",
    "\n",
    "# 1. Se realiza la corrección de los tipos de datos\n",
    "# Convertir 'metascore' a numérico. 'tbd' (to be determined) se convertirá en NaN.\n",
    "df_metacritic_clean['metascore'] = pd.to_numeric(df_metacritic_clean['metascore'], errors='coerce')\n",
    "\n",
    "# Se convierte 'release_date' a formato de fecha\n",
    "df_metacritic_clean['release_date'] = pd.to_datetime(df_metacritic_clean['release_date'], errors='coerce')\n",
    "\n",
    "# 2. Se corrige nulos (los que se crearon al forzar la conversión)\n",
    "# Se rellenan los metascores nulos con 0 o la media, optamos por la media.\n",
    "metascore_mean = df_metacritic_clean['metascore'].mean()\n",
    "df_metacritic_clean['metascore'] = df_metacritic_clean['metascore'].fillna(metascore_mean)\n",
    "df_metacritic_clean['metascore'] = df_metacritic_clean['metascore'].astype(int)\n",
    "\n",
    "# 3. Verificación\n",
    "print(\"Información del DataFrame df_metacritic después de la limpieza:\")\n",
    "df_metacritic_clean.info()\n",
    "print(\"\\nPrimeras filas del DataFrame limpio:\")\n",
    "print(df_metacritic_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dd40ed5-dcdd-40a1-8158-f0ba538ffd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando análisis de sentimientos en reseñas de Yelp... ---\n",
      "Análisis de Yelp completado.\n",
      "\n",
      "--- Iniciando análisis de sentimientos en resúmenes de Metacritic... ---\n",
      "Análisis de Metacritic completado.\n",
      "\n",
      "--- Resultados del Análisis de Sentimientos ---\n",
      "\n",
      "Distribución de sentimientos en Yelp:\n",
      "sentiment\n",
      "Positivo    430401\n",
      "Negativo     63577\n",
      "Neutral       6022\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Promedio de estrellas por tipo de sentimiento en Yelp:\n",
      "sentiment\n",
      "Negativo    1.696903\n",
      "Neutral     2.550648\n",
      "Positivo    4.135848\n",
      "Name: stars, dtype: float64\n",
      "\n",
      "Distribución de sentimientos en Metacritic:\n",
      "sentiment\n",
      "Positivo    1270\n",
      "Negativo     979\n",
      "Neutral      127\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Parte 3: Realizar Análisis de Sentimientos\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Se inicializa el analizador de sentimientos\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 2. Función para clasificar el sentimiento\n",
    "def get_sentiment(text):\n",
    "    # El 'compound score' es una métrica de -1 (muy negativo) a +1 (muy positivo)\n",
    "    score = analyzer.polarity_scores(text)['compound']\n",
    "    if score >= 0.05:\n",
    "        return 'Positivo'\n",
    "    elif score <= -0.05:\n",
    "        return 'Negativo'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Análisis de Reseñas de Yelp\n",
    "print(\"--- Iniciando análisis de sentimientos en reseñas de Yelp... ---\")\n",
    "# Demora por la cantidad de datos (500.000)\n",
    "df_yelp_clean['sentiment'] = df_yelp_clean['text'].apply(get_sentiment)\n",
    "print(\"Análisis de Yelp completado.\")\n",
    "\n",
    "# Análisis de Resúmenes de Metacritic (descripción)\n",
    "print(\"\\n--- Iniciando análisis de sentimientos en resúmenes de Metacritic... ---\")\n",
    "df_metacritic_clean['sentiment'] = df_metacritic_clean['summary'].apply(get_sentiment)\n",
    "print(\"Análisis de Metacritic completado.\")\n",
    "\n",
    "\n",
    "# Análisis Rápido de los Resultados\n",
    "print(\"\\n--- Resultados del Análisis de Sentimientos ---\")\n",
    "\n",
    "# Conteo de tipos de sentimiento en las reseñas de Yelp\n",
    "print(\"\\nDistribución de sentimientos en Yelp:\")\n",
    "print(df_yelp_clean['sentiment'].value_counts())\n",
    "\n",
    "# Relación entre el sentimiento de la reseña y las estrellas dadas\n",
    "print(\"\\nPromedio de estrellas por tipo de sentimiento en Yelp:\")\n",
    "print(df_yelp_clean.groupby('sentiment')['stars'].mean())\n",
    "\n",
    "# Conteo de tipos de sentimiento en los resúmenes de Metacritic\n",
    "print(\"\\nDistribución de sentimientos en Metacritic:\")\n",
    "print(df_metacritic_clean['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad1efb6a-6979-45a1-bc3e-431f094f7472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>if you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>i've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>family diner. had the buffet. eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>wow!  yummy, different,  delicious.   our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>q4Z6NCR1IMRdpPorTD89Tg</td>\n",
       "      <td>-QwHN9KoluPcA0YFllwFYQ</td>\n",
       "      <td>5</td>\n",
       "      <td>we won the playoff game last night and is sche...</td>\n",
       "      <td>2021-06-30 16:14:03</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>KTg0i04SbVWGWHHJmGOI_A</td>\n",
       "      <td>t_v2TyjeqaRkrfZKudY9cA</td>\n",
       "      <td>5</td>\n",
       "      <td>we have been a resident almost 4 years at manz...</td>\n",
       "      <td>2021-03-24 20:21:27</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>ZuMNAPcArFtaGufe-nwGOA</td>\n",
       "      <td>3XirYkP9PJvVXIEDPNNXLA</td>\n",
       "      <td>4</td>\n",
       "      <td>this place is hyped as one of the best places ...</td>\n",
       "      <td>2021-07-03 04:51:07</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>Lohri9uZyvoNnH5z_NT6DA</td>\n",
       "      <td>gfPDLZimZu1NtBIDbeXetg</td>\n",
       "      <td>2</td>\n",
       "      <td>saw the reviews so thought i'd try this place....</td>\n",
       "      <td>2019-04-16 23:28:41</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>9BaxxfWBmIsSPlx-kvRBDw</td>\n",
       "      <td>sWCCxY1-9B1FGlSVeQvnHg</td>\n",
       "      <td>5</td>\n",
       "      <td>yummy!  i ordered uber eats and wasn't sure ho...</td>\n",
       "      <td>2021-07-06 01:58:08</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_id             business_id  stars  \\\n",
       "0       KU_O5udG6zpxOg-VcAEodg  XQfwVwDr-v0ZS3_CbbE5Xw      3   \n",
       "1       BiTunyQ73aT9WBnpR9DZGw  7ATYjTIgM3jUlt4UM3IypQ      5   \n",
       "2       saUsX_uimxRlCVr67Z4Jig  YjUWPpI6HXG530lwP-fb2A      3   \n",
       "3       AqPFMleE6RsU23_auESxiA  kxX2SOes4o-D3ZQBkiMRfA      5   \n",
       "4       Sx8TMOWLNuJBWer-0pcmoA  e4Vwtrqf-wpJfwesgvdgxQ      4   \n",
       "...                        ...                     ...    ...   \n",
       "499995  q4Z6NCR1IMRdpPorTD89Tg  -QwHN9KoluPcA0YFllwFYQ      5   \n",
       "499996  KTg0i04SbVWGWHHJmGOI_A  t_v2TyjeqaRkrfZKudY9cA      5   \n",
       "499997  ZuMNAPcArFtaGufe-nwGOA  3XirYkP9PJvVXIEDPNNXLA      4   \n",
       "499998  Lohri9uZyvoNnH5z_NT6DA  gfPDLZimZu1NtBIDbeXetg      2   \n",
       "499999  9BaxxfWBmIsSPlx-kvRBDw  sWCCxY1-9B1FGlSVeQvnHg      5   \n",
       "\n",
       "                                                     text                date  \\\n",
       "0       if you decide to eat here, just be aware it is... 2018-07-07 22:09:11   \n",
       "1       i've taken a lot of spin classes over the year... 2012-01-03 15:28:18   \n",
       "2       family diner. had the buffet. eclectic assortm... 2014-02-05 20:30:30   \n",
       "3       wow!  yummy, different,  delicious.   our favo... 2015-01-04 00:01:03   \n",
       "4       cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15   \n",
       "...                                                   ...                 ...   \n",
       "499995  we won the playoff game last night and is sche... 2021-06-30 16:14:03   \n",
       "499996  we have been a resident almost 4 years at manz... 2021-03-24 20:21:27   \n",
       "499997  this place is hyped as one of the best places ... 2021-07-03 04:51:07   \n",
       "499998  saw the reviews so thought i'd try this place.... 2019-04-16 23:28:41   \n",
       "499999  yummy!  i ordered uber eats and wasn't sure ho... 2021-07-06 01:58:08   \n",
       "\n",
       "       sentiment  \n",
       "0       Positivo  \n",
       "1       Positivo  \n",
       "2       Positivo  \n",
       "3       Positivo  \n",
       "4       Positivo  \n",
       "...          ...  \n",
       "499995  Positivo  \n",
       "499996  Positivo  \n",
       "499997  Positivo  \n",
       "499998  Positivo  \n",
       "499999  Positivo  \n",
       "\n",
       "[500000 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "102ae5e5-c9f9-4b01-9fb9-ee2d5d7f4a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motor de SQLAlchemy creado. Intentando conectar...\n",
      "¡Conexión a SQL Server exitosa!\n",
      "Cargando 'df_vgsales_clean' a la tabla 'VentasVideojuegos'...\n",
      "Tabla 'VentasVideojuegos' cargada.\n",
      "Cargando 'df_movies_clean' a la tabla 'Peliculas'...\n",
      "Tabla 'Peliculas' cargada.\n",
      "Cargando 'df_yelp_clean' a la tabla 'ResenasYelp'...\n",
      "Tabla 'ResenasYelp' cargada.\n",
      "Cargando 'df_metacritic_clean' a la tabla 'ResenasMetacritic'...\n",
      "Tabla 'ResenasMetacritic' cargada.\n",
      "\n",
      "¡Proceso de carga a SQL Server completado!\n",
      "\n",
      "Verificando datos: Leyendo las 5 primeras filas de la tabla 'VentasVideojuegos' desde SQL Server...\n",
      "   Rank                      Name Platform  Year         Genre Publisher  \\\n",
      "0     1                Wii Sports      Wii  2006        Sports  Nintendo   \n",
      "1     2         Super Mario Bros.      NES  1985      Platform  Nintendo   \n",
      "2     3            Mario Kart Wii      Wii  2008        Racing  Nintendo   \n",
      "3     4         Wii Sports Resort      Wii  2009        Sports  Nintendo   \n",
      "4     5  Pokemon Red/Pokemon Blue       GB  1996  Role-Playing  Nintendo   \n",
      "\n",
      "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
      "0     41.49     29.02      3.77         8.46         82.74  \n",
      "1     29.08      3.58      6.81         0.77         40.24  \n",
      "2     15.85     12.88      3.79         3.31         35.82  \n",
      "3     15.75     11.01      3.28         2.96         33.00  \n",
      "4     11.27      8.89     10.22         1.00         31.37  \n"
     ]
    }
   ],
   "source": [
    "# Parte 5: Conectar y cargar datos a SQL Server\n",
    "\n",
    "# Credenciales de conexión\n",
    "server = 'proyecto-analisis-de-datos.database.windows.net'  # Ej: mi-servidor-epn.database.windows.net\n",
    "database = 'ProyectoFinalDB'          # Ej: ProyectoAnalitica\n",
    "username = 'admin-epn'                 # Ej: admin_user\n",
    "password = 'Brandon.2.0'\n",
    "driver = 'ODBC Driver 17 for SQL Server' # No cambiar esto\n",
    "\n",
    "# Contrucción del motor de conexión con SQLAlchemy\n",
    "# Este formato de URL es el que entiende SQLAlchemy para conectarse\n",
    "connection_string = f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver}\"\n",
    "engine = sqlalchemy.create_engine(connection_string)\n",
    "\n",
    "print(\"Motor de SQLAlchemy creado. Intentando conectar...\")\n",
    "\n",
    "try:\n",
    "    # Se carga cada DataFrame a una tabla en SQL Server\n",
    "    # Se usa un bloque try-except para manejar posibles errores de conexión\n",
    "    with engine.connect() as conn:\n",
    "        print(\"¡Conexión a SQL Server exitosa!\")\n",
    "\n",
    "        # 1. Se carga df_vgsales_clean\n",
    "        print(\"Cargando 'df_vgsales_clean' a la tabla 'VentasVideojuegos'...\")\n",
    "        df_vgsales_clean.to_sql('VentasVideojuegos', con=conn, if_exists='replace', index=False, chunksize=1000)\n",
    "        print(\"Tabla 'VentasVideojuegos' cargada.\")\n",
    "\n",
    "        # 2. Se carga df_movies_clean\n",
    "        print(\"Cargando 'df_movies_clean' a la tabla 'Peliculas'...\")\n",
    "        # Usamos chunksize para manejar la memoria con DataFrames grandes\n",
    "        df_movies_clean.to_sql('Peliculas', con=conn, if_exists='replace', index=False, chunksize=1000)\n",
    "        print(\"Tabla 'Peliculas' cargada.\")\n",
    "\n",
    "        # 3. Se carga df_yelp_clean\n",
    "        print(\"Cargando 'df_yelp_clean' a la tabla 'ResenasYelp'...\")\n",
    "        df_yelp_clean.to_sql('ResenasYelp', con=conn, if_exists='replace', index=False, chunksize=1000)\n",
    "        print(\"Tabla 'ResenasYelp' cargada.\")\n",
    "\n",
    "        # 4. Se carga df_metacritic_clean\n",
    "        print(\"Cargando 'df_metacritic_clean' a la tabla 'ResenasMetacritic'...\")\n",
    "        df_metacritic_clean.to_sql('ResenasMetacritic', con=conn, if_exists='replace', index=False, chunksize=1000)\n",
    "        print(\"Tabla 'ResenasMetacritic' cargada.\")\n",
    "\n",
    "        print(\"\\n¡Proceso de carga a SQL Server completado!\")\n",
    "\n",
    "        # Verificación\n",
    "        print(\"\\nVerificando datos: Leyendo las 5 primeras filas de la tabla 'VentasVideojuegos' desde SQL Server...\")\n",
    "        df_from_sql = pd.read_sql(\"SELECT TOP 5 * FROM VentasVideojuegos\", conn)\n",
    "        print(df_from_sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError durante la conexión o carga a SQL Server: {e}\")\n",
    "    print(\"Por favor, verifica tus credenciales, la configuración del firewall y que el servidor esté activo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85c974fa-de5d-4009-855f-a830e43c8181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cargando el dataset de negocios de Yelp ---\n",
      "Dataset de negocios cargado y filtrado exitosamente.\n",
      "              business_id                      name           city state  \\\n",
      "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ  Santa Barbara    CA   \n",
      "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store         Affton    MO   \n",
      "2  tUFrWirKiKi_TAnsVWINQQ                    Target         Tucson    AZ   \n",
      "3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   Philadelphia    PA   \n",
      "4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery     Green Lane    PA   \n",
      "\n",
      "                                          categories  \n",
      "0  Doctors, Traditional Chinese Medicine, Naturop...  \n",
      "1  Shipping Centers, Local Services, Notaries, Ma...  \n",
      "2  Department Stores, Shopping, Fashion, Home & G...  \n",
      "3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...  \n",
      "4                          Brewpubs, Breweries, Food  \n"
     ]
    }
   ],
   "source": [
    "# Parte 6: Relacionar la información de cada negocio registrado en Yelp y volverlo a cargar a SQL Server\n",
    "\n",
    "print(\"--- Cargando el dataset de negocios de Yelp ---\")\n",
    "try:\n",
    "    # Se carga el archivo JSON de negocios\n",
    "    df_business = pd.read_json('yelp_academic_dataset_business.json', lines=True)\n",
    "\n",
    "    # Se selecciona solo las columnas que necesitamos\n",
    "    df_business_selection = df_business[['business_id', 'name', 'city', 'state', 'categories']]\n",
    "\n",
    "    print(\"Dataset de negocios cargado y filtrado exitosamente.\")\n",
    "    print(df_business_selection.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Asegúrate de haber subido el archivo 'yelp_academic_dataset_business.json' a Colab.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c7fd630-6d5c-465e-9b6a-1f19324db1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Uniendo los DataFrames de reseñas y negocios ---\n",
      "¡Unión completada!\n"
     ]
    }
   ],
   "source": [
    "# Realiza la unión\n",
    "print(\"\\n--- Uniendo los DataFrames de reseñas y negocios ---\")\n",
    "\n",
    "# Hacemos el 'merge' (unión) usando 'business_id' como la clave\n",
    "# 'how='left'' asegura que se mantenga todas las reseñas de la tabla izquierda (df_yelp_clean)\n",
    "df_yelp_final = pd.merge(df_yelp_clean, df_business_selection, on='business_id', how='left')\n",
    "\n",
    "print(\"¡Unión completada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0b1d28b-65bc-42bd-a06c-6550c1093684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verificación del DataFrame final de Yelp ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   review_id    500000 non-null  object        \n",
      " 1   business_id  500000 non-null  object        \n",
      " 2   stars        500000 non-null  int64         \n",
      " 3   text         500000 non-null  object        \n",
      " 4   date         500000 non-null  datetime64[ns]\n",
      " 5   sentiment    500000 non-null  object        \n",
      " 6   name         500000 non-null  object        \n",
      " 7   city         500000 non-null  object        \n",
      " 8   state        500000 non-null  object        \n",
      " 9   categories   499972 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(8)\n",
      "memory usage: 38.1+ MB\n",
      "\n",
      "Primeras 5 filas del DataFrame combinado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>if you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>North Wales</td>\n",
       "      <td>PA</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch, Food, Juice B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>i've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Body Cycle Spinning Studio</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>Active Life, Cycling Classes, Trainers, Gyms, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>family diner. had the buffet. eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Kettle Restaurant</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>wow!  yummy, different,  delicious.   our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Zaika</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>Halal, Pakistani, Restaurants, Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Melt</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>Sandwiches, Beer, Wine &amp; Spirits, Bars, Food, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>q4Z6NCR1IMRdpPorTD89Tg</td>\n",
       "      <td>-QwHN9KoluPcA0YFllwFYQ</td>\n",
       "      <td>5</td>\n",
       "      <td>we won the playoff game last night and is sche...</td>\n",
       "      <td>2021-06-30 16:14:03</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Spike's Trophies</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>Printing Services, Shopping, Screen Printing/T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>KTg0i04SbVWGWHHJmGOI_A</td>\n",
       "      <td>t_v2TyjeqaRkrfZKudY9cA</td>\n",
       "      <td>5</td>\n",
       "      <td>we have been a resident almost 4 years at manz...</td>\n",
       "      <td>2021-03-24 20:21:27</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Manzanita Gate Apartments</td>\n",
       "      <td>Reno</td>\n",
       "      <td>NV</td>\n",
       "      <td>Apartments, Home Services, Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>ZuMNAPcArFtaGufe-nwGOA</td>\n",
       "      <td>3XirYkP9PJvVXIEDPNNXLA</td>\n",
       "      <td>4</td>\n",
       "      <td>this place is hyped as one of the best places ...</td>\n",
       "      <td>2021-07-03 04:51:07</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Crown Candy Kitchen</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>MO</td>\n",
       "      <td>Specialty Food, Food, American (Traditional), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>Lohri9uZyvoNnH5z_NT6DA</td>\n",
       "      <td>gfPDLZimZu1NtBIDbeXetg</td>\n",
       "      <td>2</td>\n",
       "      <td>saw the reviews so thought i'd try this place....</td>\n",
       "      <td>2019-04-16 23:28:41</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Nirvana Indian Bistro</td>\n",
       "      <td>Lafayette Hill</td>\n",
       "      <td>PA</td>\n",
       "      <td>Restaurants, Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>9BaxxfWBmIsSPlx-kvRBDw</td>\n",
       "      <td>sWCCxY1-9B1FGlSVeQvnHg</td>\n",
       "      <td>5</td>\n",
       "      <td>yummy!  i ordered uber eats and wasn't sure ho...</td>\n",
       "      <td>2021-07-06 01:58:08</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>CD Roma Restaurant</td>\n",
       "      <td>St Petersburg</td>\n",
       "      <td>FL</td>\n",
       "      <td>Restaurants, Wine Bars, Italian, Food, Sandwic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_id             business_id  stars  \\\n",
       "0       KU_O5udG6zpxOg-VcAEodg  XQfwVwDr-v0ZS3_CbbE5Xw      3   \n",
       "1       BiTunyQ73aT9WBnpR9DZGw  7ATYjTIgM3jUlt4UM3IypQ      5   \n",
       "2       saUsX_uimxRlCVr67Z4Jig  YjUWPpI6HXG530lwP-fb2A      3   \n",
       "3       AqPFMleE6RsU23_auESxiA  kxX2SOes4o-D3ZQBkiMRfA      5   \n",
       "4       Sx8TMOWLNuJBWer-0pcmoA  e4Vwtrqf-wpJfwesgvdgxQ      4   \n",
       "...                        ...                     ...    ...   \n",
       "499995  q4Z6NCR1IMRdpPorTD89Tg  -QwHN9KoluPcA0YFllwFYQ      5   \n",
       "499996  KTg0i04SbVWGWHHJmGOI_A  t_v2TyjeqaRkrfZKudY9cA      5   \n",
       "499997  ZuMNAPcArFtaGufe-nwGOA  3XirYkP9PJvVXIEDPNNXLA      4   \n",
       "499998  Lohri9uZyvoNnH5z_NT6DA  gfPDLZimZu1NtBIDbeXetg      2   \n",
       "499999  9BaxxfWBmIsSPlx-kvRBDw  sWCCxY1-9B1FGlSVeQvnHg      5   \n",
       "\n",
       "                                                     text                date  \\\n",
       "0       if you decide to eat here, just be aware it is... 2018-07-07 22:09:11   \n",
       "1       i've taken a lot of spin classes over the year... 2012-01-03 15:28:18   \n",
       "2       family diner. had the buffet. eclectic assortm... 2014-02-05 20:30:30   \n",
       "3       wow!  yummy, different,  delicious.   our favo... 2015-01-04 00:01:03   \n",
       "4       cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15   \n",
       "...                                                   ...                 ...   \n",
       "499995  we won the playoff game last night and is sche... 2021-06-30 16:14:03   \n",
       "499996  we have been a resident almost 4 years at manz... 2021-03-24 20:21:27   \n",
       "499997  this place is hyped as one of the best places ... 2021-07-03 04:51:07   \n",
       "499998  saw the reviews so thought i'd try this place.... 2019-04-16 23:28:41   \n",
       "499999  yummy!  i ordered uber eats and wasn't sure ho... 2021-07-06 01:58:08   \n",
       "\n",
       "       sentiment                          name            city state  \\\n",
       "0       Positivo  Turning Point of North Wales     North Wales    PA   \n",
       "1       Positivo    Body Cycle Spinning Studio    Philadelphia    PA   \n",
       "2       Positivo             Kettle Restaurant          Tucson    AZ   \n",
       "3       Positivo                         Zaika    Philadelphia    PA   \n",
       "4       Positivo                          Melt     New Orleans    LA   \n",
       "...          ...                           ...             ...   ...   \n",
       "499995  Positivo              Spike's Trophies    Philadelphia    PA   \n",
       "499996  Positivo     Manzanita Gate Apartments            Reno    NV   \n",
       "499997  Positivo           Crown Candy Kitchen       St. Louis    MO   \n",
       "499998  Positivo         Nirvana Indian Bistro  Lafayette Hill    PA   \n",
       "499999  Positivo            CD Roma Restaurant   St Petersburg    FL   \n",
       "\n",
       "                                               categories  \n",
       "0       Restaurants, Breakfast & Brunch, Food, Juice B...  \n",
       "1       Active Life, Cycling Classes, Trainers, Gyms, ...  \n",
       "2                         Restaurants, Breakfast & Brunch  \n",
       "3                   Halal, Pakistani, Restaurants, Indian  \n",
       "4       Sandwiches, Beer, Wine & Spirits, Bars, Food, ...  \n",
       "...                                                   ...  \n",
       "499995  Printing Services, Shopping, Screen Printing/T...  \n",
       "499996             Apartments, Home Services, Real Estate  \n",
       "499997  Specialty Food, Food, American (Traditional), ...  \n",
       "499998                                Restaurants, Indian  \n",
       "499999  Restaurants, Wine Bars, Italian, Food, Sandwic...  \n",
       "\n",
       "[500000 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verficación\n",
    "print(\"\\n--- Verificación del DataFrame final de Yelp ---\")\n",
    "\n",
    "# Muestra la información para ver las nuevas columnas\n",
    "df_yelp_final.info()\n",
    "\n",
    "# Muestra las primeras filas para ver cómo se ven los datos combinados\n",
    "# Ahora deberías ver el nombre del negocio y su ciudad junto a cada reseña\n",
    "print(\"\\nPrimeras 5 filas del DataFrame combinado:\")\n",
    "df_yelp_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26a6cfa7-b024-41db-ab7a-b5ed35bda7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando el DataFrame final de Yelp a la tabla 'ResenasYelp'...\n",
      "¡Tabla 'ResenasYelp' reescrita exitosamente con la información de los negocios!\n"
     ]
    }
   ],
   "source": [
    "# Reescribe la tabla de Yelp en SQL Server\n",
    "\n",
    "print(\"Cargando el DataFrame final de Yelp a la tabla 'ResenasYelp'...\")\n",
    "\n",
    "# Usamos if_exists='replace' para borrar la tabla vieja y crear la nueva\n",
    "df_yelp_final.to_sql('ResenasYelp', \n",
    "                     con=engine.connect(), \n",
    "                     if_exists='replace',\n",
    "                     index=False, \n",
    "                     chunksize=1000)\n",
    "\n",
    "print(\"¡Tabla 'ResenasYelp' reescrita exitosamente con la información de los negocios!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb0eb3-927a-4b34-89ce-b78c4fce23a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
